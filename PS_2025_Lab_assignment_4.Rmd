---
title: 'P&S-2025: Lab assignment 4'
author: "Lidiia Sokha, Oleksandr Lykhanskyi, Mariia Krasniukevych"
output: html_document
date: "2025-11-29"
---

#Problem1
```{r}

```
#Problem2
```{r}

```
#Problem3

```{r}
#Saving data
n <- 37
k_nums <- 1:150

#Making a_function from the task
a_function <- function(k, n) {
  x <- k * log(k^2 * n + pi)
  x - floor(x)
}

#Data for observation
a_data <- a_function(k_nums, n)
x <- qnorm(a_data[1:100])
y <- qnorm(a_data[101:150])

mu_hat <- mean(x)
sigma_hat <- sd(x)

#(a)
ks_test1 <- ks.test(x, "pnorm", mean = mu_hat, sd = sigma_hat)
cat("Part (a)")
ks_test1

#(b)
lambda <- 1
ks_test2 <- ks.test(x, "pexp", rate = lambda)
cat("Part (b)")
ks_test2

#(c)
ks_test3 <- ks.test(x, y)
cat("Part (c)")
ks_test3

```
## Main concept of KS test:

**The Kolmogorov-Smirnov test is a non-parametric (usually, here we have an exception in part (a)) goodness-of-fit test.**

There is two types of KS test:

-   **One-sampled KS test:**

Comparing **empirical CDF** of given sample with a **theoretical CDF**

-   **Two-sampled KS test**

Comparing **empirical CDF** of two given samples (in our case X and Y)

The test-statistic here is:

$D = \sup_{x} \left| F_n(x) - F(x) \right|$

which shows the biggest distance between two **CDFs.**

In a result we can say that we comparing two hypothesis:

$H_0$: two samples come from the same distribution,

$H_1$: two samples come from different distributions.

And $p$-value tells if the distance large enough to reject $H_0$.

## Explanation of the test results:

**Part(a):**

$D = 0.069821,p-value = 0.7142$

The small value of $D$ shows that distance between **empirical CDF** and **theoretical CDF** is really small.

Big value of $p-value$ shows that we don't have enough evidence to reject $H_0$

**Part(b):**

$D=0.53293, p-value < 2.2e-16$

Big value of $D$ shows that distance between **empirical CDF** and **theoretical CDF** is too large to observe they're from the same distribution.

Small *(close to zero)* value of $p-value$ shows that we have strong evidance to reject $H_0$

**Part(с):**

$D=0.11, p-value = 0.8042$

The small value of $D$ shows that distance between two **empirical CDFs** is really small and we can observe they're from the same distribution.

Big value of $p-value$ shows that we don't have enough evidence to reject $H_0$

## Here are visualizations of empirical and theoretical CDFs for all tests
```{r}
Fn_x <- ecdf(x)
Fn_y <- ecdf(y)

#Part(a)
plot(Fn_x,
     main = "Part (a): Empirical CDF vs Normal CDF",
     xlab = "x",
     ylab = "CDF",
     col = "blue",
     lwd = 2)

xx <- seq(min(x), max(x), length.out = 500)
lines(xx, pnorm(xx, mean = mu_hat, sd = sigma_hat),
      col = "red", lwd = 2)


#Part(b)
plot(Fn_x,
     main = "Part (b): Empirical CDF vs Exponential CDF",
     xlab = "x",
     ylab = "CDF",
     col = "blue",
     lwd = 2)

xx_b <- seq(min(x), max(x), length.out = 500)
lines(xx_b, pexp(xx_b, rate = lambda),
      col = "red", lwd = 2)

#Part(c)
plot(Fn_x,
     main = "Part (c): Empirical CDFs of X and Y",
     xlab = "x",
     ylab = "CDF",
     col = "blue",
     lwd = 2)

lines(Fn_y, col = "darkred", lwd = 2)
```

#Problem4
```{r}

```
